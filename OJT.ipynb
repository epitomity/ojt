{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6428875c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from gensim import corpora\n",
    "from gensim.models import LdaModel\n",
    "from gensim.utils import simple_preprocess\n",
    "from nltk.corpus import stopwords\n",
    "from collections import Counter\n",
    "from itertools import product\n",
    "\n",
    "\n",
    "import bitermplus as btm\n",
    "import tmplot as tmp\n",
    "\n",
    "import torch\n",
    "from transformers import DistilBertTokenizer, DistilBertModel\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import re\n",
    "\n",
    "import gensim.corpora as corpora\n",
    "from gensim.models.coherencemodel import CoherenceModel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e252a8da",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\github\\ojt\\.conda\\lib\\site-packages\\gensim\\topic_coherence\\direct_confirmation_measure.py:204: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  m_lr_i = np.log(numerator / denominator)\n",
      "d:\\github\\ojt\\.conda\\lib\\site-packages\\gensim\\topic_coherence\\indirect_confirmation_measure.py:323: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  return cv1.T.dot(cv2)[0, 0] / (_magnitude(cv1) * _magnitude(cv2))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'num_topics': 10, 'alpha': 'symmetric', 'passes': 5, 'coherence_score': nan}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#LDA==========================================================================================================\n",
    "#https://radimrehurek.com/gensim/models/ldamodel.html\n",
    "\n",
    "#read the txt file\n",
    "with open(r'cleaned_tweets.txt') as file:\n",
    "    data = file.readlines()\n",
    "\n",
    "# create a dataframe\n",
    "df = pd.DataFrame(data, columns=['text'])\n",
    "\n",
    "# write dataframe to csv file\n",
    "df.to_csv('cleaned_tweets.csv', index=False)\n",
    "data = pd.read_csv('cleaned_tweets.csv')\n",
    "\n",
    "# preprocess text data\n",
    "stop_words = stopwords.words('english')\n",
    "\n",
    "def preprocess(text):\n",
    "    result = []\n",
    "    for token in simple_preprocess(text):\n",
    "        if token not in stop_words:\n",
    "            result.append(token)\n",
    "    return result\n",
    "\n",
    "data['processed_text'] = data['text'].apply(preprocess)\n",
    "\n",
    "# Tokenize the documents\n",
    "tokenized_docs = [doc.split() for doc in data]\n",
    "# create dictionary and corpus\n",
    "dictionary = corpora.Dictionary(data['processed_text'])\n",
    "corpus = [dictionary.doc2bow(text) for text in data['processed_text']]\n",
    "\n",
    "# Define the range of hyperparameter values to search over\n",
    "num_topics_list = [10]\n",
    "passes_list = [5, 10, 15]\n",
    "alpha_list = ['symmetric',0.3,0.5,0.7]\n",
    "\n",
    "# Perform a grid search over the hyperparameter values\n",
    "results = []\n",
    "for num_topics, passes , alpha in product(num_topics_list, passes_list,alpha_list):\n",
    "    lda_model = LdaModel(corpus=corpus, id2word=dictionary, num_topics=num_topics, passes=passes,alpha=alpha,)\n",
    "    coherence_model = CoherenceModel(model=lda_model, texts=tokenized_docs, dictionary=dictionary, coherence='c_v')\n",
    "    coherence_score = coherence_model.get_coherence()\n",
    "    results.append({'num_topics': num_topics,'alpha':alpha, 'passes': passes, 'coherence_score': coherence_score})\n",
    "\n",
    "# Find the hyperparameters with the highest coherence score\n",
    "best_params = max(results, key=lambda x: x['coherence_score'])\n",
    "print('Best parameters:', best_params)\n",
    "\n",
    "\n",
    "#Best parameters: {'num_topics': 10, 'alpha': 'symmetric', 'passes': 5, 'coherence_score': nan}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "290ccbeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train LDA model\n",
    "lda_model = LdaModel(corpus=corpus, id2word=dictionary, num_topics=10, alpha='symmetric',passes=5)\n",
    "\n",
    "# print top topics and their keywords\n",
    "for topic in lda_model.show_topics(num_topics=num_topics, num_words=10, formatted=False):\n",
    "    print('Topic {}: {}'.format(topic[0], [word[0] for word in topic[1]]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e8aacaf6",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 15\u001b[0m\n\u001b[0;32m     13\u001b[0m docs_lens \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(\u001b[39mmap\u001b[39m(\u001b[39mlen\u001b[39m, docs_vec))\n\u001b[0;32m     14\u001b[0m \u001b[39m# Generating biterms\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m biterms \u001b[39m=\u001b[39m btm\u001b[39m.\u001b[39;49mget_biterms(docs_vec)\n\u001b[0;32m     17\u001b[0m \u001b[39m# Define hyperparameters to tune\u001b[39;00m\n\u001b[0;32m     18\u001b[0m M_list \u001b[39m=\u001b[39m [\u001b[39m10\u001b[39m, \u001b[39m15\u001b[39m, \u001b[39m20\u001b[39m]\n",
      "File \u001b[1;32md:\\github\\ojt\\.conda\\lib\\site-packages\\bitermplus\\_util.py:140\u001b[0m, in \u001b[0;36mget_biterms\u001b[1;34m(docs, win)\u001b[0m\n\u001b[0;32m    138\u001b[0m     \u001b[39mcontinue\u001b[39;00m\n\u001b[0;32m    139\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(doc_len\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m):\n\u001b[1;32m--> 140\u001b[0m     \u001b[39mfor\u001b[39;00m j \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39;49m(i\u001b[39m+\u001b[39;49m\u001b[39m1\u001b[39;49m, \u001b[39mmin\u001b[39;49m(i \u001b[39m+\u001b[39;49m win, doc_len)):\n\u001b[0;32m    141\u001b[0m         wi \u001b[39m=\u001b[39m \u001b[39mmin\u001b[39m(doc[i], doc[j])\n\u001b[0;32m    142\u001b[0m         wj \u001b[39m=\u001b[39m \u001b[39mmax\u001b[39m(doc[i], doc[j])\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#Biterm========================================================================================================\n",
    "#https://bitermplus.readthedocs.io/en/latest/index.html\n",
    "#IMPORTING DATA\n",
    "df = pd.read_csv(\n",
    "    'cleaned_tweets.csv', header=None, names=['texts'])\n",
    "texts = df['texts'].str.strip().tolist()\n",
    "# PREPROCESSING\n",
    "# Obtaining terms frequency in a sparse matrix and corpus vocabulary\n",
    "X, vocabulary, vocab_dict = btm.get_words_freqs(texts)\n",
    "tf = np.array(X.sum(axis=0)).ravel()\n",
    "# Vectorizing documents\n",
    "docs_vec = btm.get_vectorized_docs(texts, vocabulary)\n",
    "docs_lens = list(map(len, docs_vec))\n",
    "# Generating biterms\n",
    "biterms = btm.get_biterms(docs_vec)\n",
    "\n",
    "# Define hyperparameters to tune\n",
    "M_list = [10, 15, 20]\n",
    "alpha_list = [0.01, 0.1, 1, 10]\n",
    "beta_list = [0.01, 0.1, 1, 10]\n",
    "\n",
    "# Initialize variables to hold best results\n",
    "best_score = 0\n",
    "best_params = {}\n",
    "\n",
    "# Grid search\n",
    "for M in M_list:\n",
    "    for alpha in alpha_list:\n",
    "        for beta in beta_list:\n",
    "            biterm_model = btm.BTM( X, vocabulary, T=10, M=M, alpha=alpha, beta=beta)\n",
    "            biterms = biterm_model.fit_transform(docs_vec,biterms)\n",
    "            score = biterm_model.get_word_score(biterms)\n",
    "            if score > best_score:\n",
    "                best_score = score\n",
    "                best_params = {'M': M, 'alpha': alpha, 'beta': beta}\n",
    "\n",
    "# Print best parameters and score\n",
    "print('Best parameters: {}'.format(best_params))\n",
    "print('Best score: {}'.format(best_score))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41bb3a2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# INITIALIZING AND RUNNING MODEL\n",
    "model = btm.BTM(\n",
    "    X, vocabulary, T=10, M=20, alpha=50/8, beta=0.01)\n",
    "model.fit(biterms, iterations=20)\n",
    "p_zd = model.transform(docs_vec)\n",
    "\n",
    "#METRICS\n",
    "perplexity = btm.perplexity(model.matrix_topics_words_, p_zd, X, 8)\n",
    "coherence = btm.coherence(model.matrix_topics_words_, X, M=20)\n",
    "\n",
    "topics = btm.get_top_topic_words(\n",
    "    model,\n",
    "    words_num=10,)\n",
    "print(topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c641b77",
   "metadata": {},
   "outputs": [],
   "source": [
    "#distilbert===================================================================================================\n",
    "# load the DistilBERT model and tokenizer\n",
    "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "model = DistilBertModel.from_pretrained('distilbert-base-uncased')\n",
    "\n",
    "#get document\n",
    "def get_tweet_embeddings(tweets):\n",
    "    tweet_embeddings = []\n",
    "    for tweet in tweets:\n",
    "        print (len(tweet_embeddings))\n",
    "        # Remove URLs and mentions\n",
    "        tweet = re.sub(r\"http\\S+|@\\S+\", \"\", tweet)\n",
    "        # Tokenize the tweet\n",
    "        tokens = tokenizer.encode(tweet, add_special_tokens=True)\n",
    "        # Convert tokens to tensor\n",
    "        tokens_tensor = torch.tensor(tokens).unsqueeze(0)\n",
    "        # Get the embeddings\n",
    "        with torch.no_grad():\n",
    "            outputs = model(tokens_tensor)\n",
    "        tweet_embedding = outputs[0][:, 0, :].numpy().squeeze()\n",
    "        tweet_embeddings.append(tweet_embedding)\n",
    "    return tweet_embeddings\n",
    "\n",
    "#perform LDA in document\n",
    "def perform_lda(embeddings, num_topics):\n",
    "    print(\"performing lda training\")\n",
    "    vectorizer = CountVectorizer(max_df=0.95, min_df=2, stop_words='english')\n",
    "    dtm = vectorizer.fit_transform(embeddings)\n",
    "    lda = LatentDirichletAllocation(n_components=num_topics, random_state=42)\n",
    "    lda.fit(dtm)\n",
    "    return lda, dtm, vectorizer\n",
    "#train\n",
    "#read the txt file\n",
    "df = pd.read_csv(\n",
    "    'cleaned_tweets.csv', header=None, names=['texts'])\n",
    "tweets = df['texts'].str.strip().tolist()\n",
    "tweet_embeddings = get_tweet_embeddings(tweets)\n",
    "lda, dtm, vectorizer = perform_lda(tweet_embeddings, num_topics=2)\n",
    "\n",
    "for i, topic in enumerate(lda.components_):\n",
    "    top_words_idx = topic.argsort()[:-5-1:-1]\n",
    "    top_words = [vectorizer.get_feature_names()[i] for i in top_words_idx]\n",
    "    print(f'Topic {i}: {\", \".join(top_words)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8778cba4",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b51ddddd",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66734f6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\\n==========================================COHERENCE=============================================\\n\\n\")\n",
    "\n",
    "#Reg exp for tokenizing the data set\n",
    "tokenizer = lambda s: re.findall('\\w+', s.lower())\n",
    "text = [tokenizer(t) for t in data]\n",
    "\n",
    "# Getting Topics\n",
    "all_topics = topic_model.get_topics()\n",
    "top = []\n",
    "keys = []\n",
    "for x in range(10):\n",
    "    keys.append(freq['Topic'].head(10)[x])\n",
    "\n",
    "#Tokenizing\n",
    "prefix = 'Getting Topics'\n",
    "pbar2 = tqdm(total=len(keys), position=0, leave=True)\n",
    "pbar2.set_description(prefix)\n",
    "for key in tqdm(keys, desc='Getting Topics', position=0, leave=True):\n",
    "    values = all_topics[key]\n",
    "    topic_1 = []\n",
    "    for value in tqdm(values, desc='Retrieving Values in topic ' + str(key), position=0, leave=True):\n",
    "        topic_1.append(value[0])\n",
    "    top.append(topic_1)\n",
    "\n",
    "# Creating a dictionary with the vocabulary\n",
    "word2id = Dictionary(text)\n",
    "vec = CountVectorizer()\n",
    "X = vec.fit_transform(data).toarray()\n",
    "vocab = np.array(vec.get_feature_names())\n",
    "# Coherence model\n",
    "cm = CoherenceModel(topics=top, texts=text, coherence='u_mass', dictionary=word2id)\n",
    "coherence_per_topic = cm.get_coherence_per_topic()\n",
    "#Results\n",
    "print(\"\\n==========================================COHERENCE RESULTS=============================================\\n\")\n",
    "for index, x in enumerate(coherence_per_topic):\n",
    "    print(\"topic %2d : %5.2f\" % (index + 1, x))\n",
    "\n",
    "coherence = cm.get_coherence()\n",
    "print(coherence)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c752697e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#bertopic===================================================================================================\n",
    "\n",
    "# Read Stopwords_EN_TL.txt and save it into a pandas DataFrame\n",
    "stop_words_dataframe = pd.read_csv(\"Stopwords_EN_TL.txt\")\n",
    "stop_words = set(stop_words_dataframe.iloc[:,0])\n",
    "# Read csv and save into a pandas DataFrame\n",
    "docs_dataframe = pd.read_csv(\"cleaned_tweets.txt\")\n",
    "# Remove stopwords for every comment and clean the dataset\n",
    "docs = []\n",
    "index = 0\n",
    "for w in docs_dataframe.iloc[:,0].items():\n",
    "    series = hero.remove_stopwords(pd.Series(w[1]),stop_words)\n",
    "    series = hero.preprocessing.clean(series)\n",
    "    docs.append(series[0])\n",
    "# Output the cleaned dataset to an excel file\n",
    "cleaned_dataset = pd.DataFrame(docs)\n",
    "cleaned_dataset.to_excel(\"cleaned_tweets.xlsx\")\n",
    "# Initialize the model and fit it to the data\n",
    "\n",
    "# Hyperparameters:\n",
    "# language - \"english\" or \"multilingual\"\n",
    "# top_n_words - the top_n_words in each topic (no effect)\n",
    "# n_gram_range - the n-gram to be used by the vectorizer in the model (no effect / incoherent)\n",
    "# min_topic_size - how big a topic should be, adjusted to be similar to LDA\n",
    "# nr_topics - topic reduction, made topics more incoherent\n",
    "\n",
    "topic_model = BERTopic(min_topic_size=25, language = \"multilingual\")\n",
    "topics, probs = topic_model.fit_transform(docs)\n",
    "# Print the topics found by the model\n",
    "topics = topic_model.get_topic_info()\n",
    "topics.to_excel(\"output.xlsx\")\n",
    "topics\n",
    "# Extract vectorizer and tokenizer from BERTopic\n",
    "vectorizer = topic_model.vectorizer_model\n",
    "tokenizer = vectorizer.build_tokenizer()\n",
    "\n",
    "# Extract features for Topic Coherence evaluation\n",
    "tokens = [tokenizer(doc) for doc in docs]\n",
    "dictionary = corpora.Dictionary(tokens)\n",
    "\n",
    "topic_words = [[words for words, _ in topic_model.get_topic(topic)] \n",
    "               for topic in range(len(set(topics))-1)]\n",
    "\n",
    "# Evaluate\n",
    "coherence_model = CoherenceModel(topics=topic_words,\n",
    "                                 texts=tokens,\n",
    "                                 dictionary=dictionary, \n",
    "                                 coherence='c_v')\n",
    "\n",
    "# Print Coherence\n",
    "coherence = coherence_model.get_coherence()\n",
    "coherence\n",
    "topic_model.visualize_barchart()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6428875c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from gensim import corpora\n",
    "from gensim.models import LdaModel\n",
    "from gensim.utils import simple_preprocess\n",
    "from nltk.corpus import stopwords\n",
    "from collections import Counter\n",
    "\n",
    "import bitermplus as btm\n",
    "import tmplot as tmp\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from umap import UMAP\n",
    "from hdbscan import HDBSCAN\n",
    "from bertopic import BERTopic\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import re\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from gensim.models.coherencemodel import CoherenceModel\n",
    "from gensim.corpora.dictionary import Dictionary\n",
    "\n",
    "import texthero as hero\n",
    "import gensim.corpora as corpora\n",
    "from gensim.models.coherencemodel import CoherenceModel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e252a8da",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#LDA==========================================================================================================\n",
    "#https://radimrehurek.com/gensim/models/ldamodel.html\n",
    "\n",
    "# read the txt file\n",
    "# with open(r'C:\\Users\\jimna\\OJT\\cleaned_tweets.txt') as file:\n",
    "#     data = file.readlines()\n",
    "\n",
    "# # create a dataframe\n",
    "# df = pd.DataFrame(data, columns=['text'])\n",
    "\n",
    "# # write dataframe to csv file\n",
    "# df.to_csv('cleaned_tweets.csv', index=False)\n",
    "# data = pd.read_csv('cleaned_tweets.csv')\n",
    "\n",
    "# # preprocess text data\n",
    "# stop_words = stopwords.words('english')\n",
    "\n",
    "# def preprocess(text):\n",
    "#     result = []\n",
    "#     for token in simple_preprocess(text):\n",
    "#         if token not in stop_words:\n",
    "#             result.append(token)\n",
    "#     return result\n",
    "\n",
    "# data['processed_text'] = data['text'].apply(preprocess)\n",
    "\n",
    "# # create dictionary and corpus\n",
    "# dictionary = corpora.Dictionary(data['processed_text'])\n",
    "# corpus = [dictionary.doc2bow(text) for text in data['processed_text']]\n",
    "\n",
    "# # train LDA model\n",
    "# num_topics = 10\n",
    "# lda_model = LdaModel(corpus=corpus, id2word=dictionary, num_topics=num_topics, random_state=42)\n",
    "\n",
    "# # print top topics and their keywords\n",
    "# for topic in lda_model.show_topics(num_topics=num_topics, num_words=10, formatted=False):\n",
    "#     print('Topic {}: {}'.format(topic[0], [word[0] for word in topic[1]]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8aacaf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Biterm========================================================================================================\n",
    "#https://bitermplus.readthedocs.io/en/latest/index.html\n",
    "# IMPORTING DATA\n",
    "# df = pd.read_csv(\n",
    "#     'cleaned_tweets.csv', header=None, names=['texts'])\n",
    "# texts = df['texts'].str.strip().tolist()\n",
    "# # PREPROCESSING\n",
    "# # Obtaining terms frequency in a sparse matrix and corpus vocabulary\n",
    "# X, vocabulary, vocab_dict = btm.get_words_freqs(texts)\n",
    "# tf = np.array(X.sum(axis=0)).ravel()\n",
    "# # Vectorizing documents\n",
    "# docs_vec = btm.get_vectorized_docs(texts, vocabulary)\n",
    "# docs_lens = list(map(len, docs_vec))\n",
    "# # Generating biterms\n",
    "# biterms = btm.get_biterms(docs_vec)\n",
    "\n",
    "# # INITIALIZING AND RUNNING MODEL\n",
    "# model = btm.BTM(\n",
    "#     X, vocabulary, seed=12321, T=10, M=20, alpha=50/8, beta=0.01)\n",
    "# model.fit(biterms, iterations=20)\n",
    "# p_zd = model.transform(docs_vec)\n",
    "\n",
    "# METRICS\n",
    "# perplexity = btm.perplexity(model.matrix_topics_words_, p_zd, X, 8)\n",
    "# coherence = btm.coherence(model.matrix_topics_words_, X, M=20)\n",
    "\n",
    "# topics = btm.get_top_topic_words(\n",
    "#     model,\n",
    "#     words_num=100,)\n",
    "# print(topics)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c641b77",
   "metadata": {},
   "outputs": [],
   "source": [
    "#distilbert===================================================================================================\n",
    "\n",
    "#resets the visualization html\n",
    "# if os.path.exists(\"TopicModels.html\"):\n",
    "#    os.remove(\"TopicModels.html\")\n",
    "\n",
    "# #Load data set\n",
    "# prefix = 'Getting comments'\n",
    "# pbar = tqdm(total=100, position=0, leave=True) #progress bar in terminal\n",
    "# pbar.set_description(prefix)\n",
    "# pbar.update(2)\n",
    "# data = open('cleaned_tweets.txt', encoding=\"utf8\").read().splitlines()\n",
    "# #Set up UMAP and HDBSCAN models for dimension reductions and clustering\n",
    "# prefix = 'Progress: Setting UMAP models and HDBSCAN models'\n",
    "# pbar.set_description(prefix)\n",
    "# pbar.update(18)\n",
    "# umap_model = UMAP(n_neighbors=3, n_components=3, min_dist=0.05)\n",
    "# hdbscan_model = HDBSCAN(min_cluster_size=5, min_samples=5, gen_min_span_tree=True, prediction_data=True)\n",
    "# #loads embeddings from embedding model\n",
    "# prefix = 'Loading embeddings'\n",
    "# pbar.set_description(prefix)\n",
    "# pbar.update(20)\n",
    "# all_embeddings = np.load('embeddings.npy')\n",
    "\n",
    "# #creates BERT model for topic modeling and fits the model to the data set\n",
    "# prefix = 'Creating BERT Topic Model'\n",
    "# pbar.set_description(prefix)\n",
    "# pbar.update(30)\n",
    "\n",
    "# topic_model = BERTopic(\n",
    "#     umap_model=umap_model,\n",
    "#     hdbscan_model=hdbscan_model,\n",
    "#     top_n_words=5,\n",
    "#     language='multilingual',\n",
    "#     calculate_probabilities=True,\n",
    "#     verbose=True\n",
    "# )\n",
    "# prefix = 'Fitting the model'\n",
    "# pbar.set_description(prefix)\n",
    "# pbar.update(10)\n",
    "# topics, probs = topic_model.fit_transform(data, embeddings=all_embeddings)\n",
    "\n",
    "# #Getting Topics for visualization and processing\n",
    "# prefix = 'Getting Topics'\n",
    "# pbar.set_description(prefix)\n",
    "# pbar.update(10)\n",
    "\n",
    "# freq = topic_model.get_topic_info()\n",
    "# top_topics = freq.head(10) #topic_model.get_topic(10)\n",
    "# len_of_topics = len(top_topics)\n",
    "\n",
    "# prefix = 'Visualizing'\n",
    "# pbar.set_description(prefix)\n",
    "# pbar.update(5)\n",
    "\n",
    "# fig1 = topic_model.visualize_topics(top_n_topics=len_of_topics)\n",
    "# fig2 = topic_model.visualize_barchart(top_n_topics=len_of_topics)\n",
    "# fig3 = topic_model.visualize_distribution(probs[200], min_probability=0.001)\n",
    "# fig4 = topic_model.visualize_hierarchy(top_n_topics=len_of_topics)\n",
    "# fig5 = topic_model.visualize_heatmap(top_n_topics=len_of_topics, width=1000, height=1000)\n",
    "# fig6 = topic_model.visualize_term_rank()\n",
    "\n",
    "# with open('TopicModels.html', 'a') as f:\n",
    "#     f.write(fig1.to_html(full_html=False, include_plotlyjs='cdn'))\n",
    "#     f.write(fig2.to_html(full_html=False, include_plotlyjs='cdn'))\n",
    "#     f.write(fig3.to_html(full_html=False, include_plotlyjs='cdn'))\n",
    "#     f.write(fig4.to_html(full_html=False, include_plotlyjs='cdn'))\n",
    "#     f.write(fig5.to_html(full_html=False, include_plotlyjs='cdn'))\n",
    "#     f.write(fig6.to_html(full_html=False, include_plotlyjs='cdn'))\n",
    "\n",
    "# print(\"\\033[A                                                                                                                                                                     \\033\", end=\"\\r\")\n",
    "# print(\" \", end=\"\\r\")\n",
    "# prefix = 'Topic Modeling Complete'\n",
    "# pbar.set_description(prefix)\n",
    "# pbar.update(5)\n",
    "# pbar.close()\n",
    "# #Coherence Metric\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66734f6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"\\n\\n==========================================COHERENCE=============================================\\n\\n\")\n",
    "\n",
    "# #Reg exp for tokenizing the data set\n",
    "# tokenizer = lambda s: re.findall('\\w+', s.lower())\n",
    "# text = [tokenizer(t) for t in data]\n",
    "\n",
    "# # Getting Topics\n",
    "# all_topics = topic_model.get_topics()\n",
    "# top = []\n",
    "# keys = []\n",
    "# for x in range(10):\n",
    "#     keys.append(freq['Topic'].head(10)[x])\n",
    "\n",
    "# #Tokenizing\n",
    "# prefix = 'Getting Topics'\n",
    "# pbar2 = tqdm(total=len(keys), position=0, leave=True)\n",
    "# pbar2.set_description(prefix)\n",
    "# for key in tqdm(keys, desc='Getting Topics', position=0, leave=True):\n",
    "#     values = all_topics[key]\n",
    "#     topic_1 = []\n",
    "#     for value in tqdm(values, desc='Retrieving Values in topic ' + str(key), position=0, leave=True):\n",
    "#         topic_1.append(value[0])\n",
    "#     top.append(topic_1)\n",
    "\n",
    "# # Creating a dictionary with the vocabulary\n",
    "# word2id = Dictionary(text)\n",
    "# vec = CountVectorizer()\n",
    "# X = vec.fit_transform(data).toarray()\n",
    "# vocab = np.array(vec.get_feature_names())\n",
    "# # Coherence model\n",
    "# cm = CoherenceModel(topics=top, texts=text, coherence='u_mass', dictionary=word2id)\n",
    "# coherence_per_topic = cm.get_coherence_per_topic()\n",
    "# #Results\n",
    "# print(\"\\n==========================================COHERENCE RESULTS=============================================\\n\")\n",
    "# for index, x in enumerate(coherence_per_topic):\n",
    "#     print(\"topic %2d : %5.2f\" % (index + 1, x))\n",
    "\n",
    "# coherence = cm.get_coherence()\n",
    "# print(coherence)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c752697e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#bertopic===================================================================================================\n",
    "\n",
    "# Read Stopwords_EN_TL.txt and save it into a pandas DataFrame\n",
    "stop_words_dataframe = pd.read_csv(\"Stopwords_EN_TL.txt\")\n",
    "stop_words = set(stop_words_dataframe.iloc[:,0])\n",
    "# Read csv and save into a pandas DataFrame\n",
    "docs_dataframe = pd.read_csv(\"cleaned_tweets.txt\")\n",
    "# Remove stopwords for every comment and clean the dataset\n",
    "docs = []\n",
    "index = 0\n",
    "for w in docs_dataframe.iloc[:,0].items():\n",
    "    series = hero.remove_stopwords(pd.Series(w[1]),stop_words)\n",
    "    series = hero.preprocessing.clean(series)\n",
    "    docs.append(series[0])\n",
    "# Output the cleaned dataset to an excel file\n",
    "cleaned_dataset = pd.DataFrame(docs)\n",
    "cleaned_dataset.to_excel(\"cleaned_tweets.xlsx\")\n",
    "# Initialize the model and fit it to the data\n",
    "\n",
    "# Hyperparameters:\n",
    "# language - \"english\" or \"multilingual\"\n",
    "# top_n_words - the top_n_words in each topic (no effect)\n",
    "# n_gram_range - the n-gram to be used by the vectorizer in the model (no effect / incoherent)\n",
    "# min_topic_size - how big a topic should be, adjusted to be similar to LDA\n",
    "# nr_topics - topic reduction, made topics more incoherent\n",
    "\n",
    "topic_model = BERTopic(min_topic_size=25, language = \"multilingual\")\n",
    "topics, probs = topic_model.fit_transform(docs)\n",
    "# Print the topics found by the model\n",
    "topics = topic_model.get_topic_info()\n",
    "topics.to_excel(\"output.xlsx\")\n",
    "topics\n",
    "# Extract vectorizer and tokenizer from BERTopic\n",
    "vectorizer = topic_model.vectorizer_model\n",
    "tokenizer = vectorizer.build_tokenizer()\n",
    "\n",
    "# Extract features for Topic Coherence evaluation\n",
    "tokens = [tokenizer(doc) for doc in docs]\n",
    "dictionary = corpora.Dictionary(tokens)\n",
    "\n",
    "topic_words = [[words for words, _ in topic_model.get_topic(topic)] \n",
    "               for topic in range(len(set(topics))-1)]\n",
    "\n",
    "# Evaluate\n",
    "coherence_model = CoherenceModel(topics=topic_words,\n",
    "                                 texts=tokens,\n",
    "                                 dictionary=dictionary, \n",
    "                                 coherence='c_v')\n",
    "\n",
    "# Print Coherence\n",
    "coherence = coherence_model.get_coherence()\n",
    "coherence\n",
    "topic_model.visualize_barchart()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
